{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load/convert data format tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor shape: torch.Size([5001, 352])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def load_npz_as_tensor(file_path):\n",
    "    # Load the npz file\n",
    "    data = np.load(file_path)\n",
    "    # Assume that the npz file contains a single array. Adjust the key as necessary.\n",
    "    key = list(data.keys())[3]\n",
    "    array = data[key]\n",
    "\n",
    "    # Convert the NumPy array to a PyTorch tensor\n",
    "    tensor = torch.tensor(array)\n",
    "\n",
    "    return tensor\n",
    "\n",
    "# Example usage\n",
    "file_path = '../FAUST_r_shot/shot_npz/tr_reg_003.npz'\n",
    "tensor = load_npz_as_tensor(file_path)\n",
    "print(\"Tensor shape:\", tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key: verts shape: (5000, 3)\n",
      "key: frames shape: (5000, 3, 3)\n",
      "key: faces shape: (9996, 3)\n",
      "key: k_eig shape: ()\n",
      "key: mass shape: (5000,)\n",
      "key: L_data shape: (34988,)\n",
      "key: L_indices shape: (34988,)\n",
      "key: L_indptr shape: (5001,)\n",
      "key: L_shape shape: (2,)\n",
      "key: evals shape: (128,)\n",
      "key: evecs shape: (5000, 128)\n",
      "key: gradX_data shape: (34988,)\n",
      "key: gradX_indices shape: (34988,)\n",
      "key: gradX_indptr shape: (5001,)\n",
      "key: gradX_shape shape: (2,)\n",
      "key: gradY_data shape: (34988,)\n",
      "key: gradY_indices shape: (34988,)\n",
      "key: gradY_indptr shape: (5001,)\n",
      "key: gradY_shape shape: (2,)\n"
     ]
    }
   ],
   "source": [
    "# check cached HKS file shape\n",
    "file_path = '../experiments/functional_correspondence/data/op_cache/1acf983c76ba9ba2de765b1a217119a6dcc54735_0.npz'\n",
    "data = np.load(file_path)\n",
    "keys = list(data.keys())\n",
    "for key in keys:\n",
    "    print(\"key:\",key,\"shape:\",data[key].shape)\n",
    "\n",
    "#key = list(data.keys())[3]\n",
    "#print(data[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key: __header__ shape: ()\n",
      "key: __version__ shape: ()\n",
      "key: __globals__ shape: (0,)\n",
      "key: shot shape: (5001, 352)\n"
     ]
    }
   ],
   "source": [
    "# check SHOT file shape\n",
    "file_path = '../FAUST_r_shot/shot_npz/tr_reg_003.npz'\n",
    "data = np.load(file_path)\n",
    "keys = list(data.keys())\n",
    "for key in keys:\n",
    "    print(\"key:\",key,\"shape:\",data[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vertices shape: (4999, 3) faces shape: (9998, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import trimesh\n",
    "import pyshot\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mesh_file = \"/root/repotest/diffusionnet/experiments/functional_correspondence/data/faust/off_2/tr_reg_003.off\"\n",
    "mesh = trimesh.load(mesh_file)\n",
    "\n",
    "v = np.array(mesh.vertices)\n",
    "f = np.array(mesh.faces)\n",
    "print('vertices shape:',v.shape, 'faces shape:',f.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute SHOT descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shot shape (5000, 672)\n"
     ]
    }
   ],
   "source": [
    "import pyshot\n",
    "import numpy as np\n",
    "import trimesh\n",
    "import argparse\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mesh_file = \"/root/repotest/diffusionnet/experiments/functional_correspondence/data/faust/off_2/tr_reg_062.off\"\n",
    "radius=100.0\n",
    "local_rf_radius=None\n",
    "min_neighbors=4\n",
    "n_bins=20\n",
    "double_volumes_sectors=True\n",
    "use_interpolation=True\n",
    "use_normalization=True\n",
    "\n",
    "mesh = trimesh.load(mesh_file)\n",
    "\n",
    "v = np.array(mesh.vertices)\n",
    "f = np.array(mesh.faces)\n",
    "\n",
    "local_rf_radius = radius if local_rf_radius is None else local_rf_radius\n",
    "\n",
    "shot_descrs = pyshot.get_descriptors(v,\n",
    "                                         f,\n",
    "                                         radius=radius,\n",
    "                                         local_rf_radius=local_rf_radius,\n",
    "                                         min_neighbors=min_neighbors,\n",
    "                                         n_bins=n_bins,\n",
    "                                         double_volumes_sectors=double_volumes_sectors,\n",
    "                                         use_interpolation=use_interpolation,\n",
    "                                         use_normalization=use_normalization,\n",
    "                                         )\n",
    "print('shot shape', shot_descrs.shape)\n",
    "# plt.imshow(shot_descrs.T)\n",
    "# plt.title(f\"SHOT descriptors of {os.path.basename(mesh_file)} (transposed)\")\n",
    "# plt.show()\n",
    "# plt.savefig(f\"{os.path.basename(mesh_file)}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine `.txt` data and store to `.pt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "def load_and_save_data(input_dir, target_file):\n",
    "    \"\"\"\n",
    "    Load data from text files in the input directory and save as a single .pt file.\n",
    "\n",
    "    Parameters:\n",
    "    input_dir (str): Directory containing the text files.\n",
    "    target_file (str): Path to save the combined .pt file.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "\n",
    "    # Iterate over files in the input directory\n",
    "    for file_name in os.listdir(input_dir):\n",
    "        file_path = os.path.join(input_dir, file_name)\n",
    "        \n",
    "        # Ensure the file is a text file\n",
    "        if os.path.isfile(file_path) and file_path.endswith('.txt'):\n",
    "            with open(file_path, 'r') as file:\n",
    "                # Read lines from the file and store them\n",
    "                lines = file.readlines()\n",
    "                data.append(lines)\n",
    "\n",
    "    # Convert the list of data to a tensor\n",
    "    data_tensor = torch.tensor(data, dtype=torch.float32)\n",
    "\n",
    "    # Save the tensor to a .pt file\n",
    "    torch.save(data_tensor, target_file)\n",
    "\n",
    "    return f\"Data from {len(data)} files saved to {target_file}\"\n",
    "\n",
    "# Example usage\n",
    "input_directory = '/path/to/input/directory'  # Replace with the actual input directory\n",
    "target_directory = '/path/to/target/directory'  # Replace with the actual target directory\n",
    "target_file_path = os.path.join(target_directory, 'combined_data.pt')\n",
    "\n",
    "load_and_save_data(input_directory, target_file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
